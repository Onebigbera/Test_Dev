## 并发和并行

[toc]

#### 一、并发和并行

#### 1.多任务

![](..\Images\manytask.png)

##### 多任务的概念

> 简单的说，就是我们的操作系统可以同时运行多个任务。

##### PU与多任务的关系：

- 单核CPU可不可以执行多个任务呢？	
  -  单核CPU也可以执行多任务，由于CPU执行代码是按照顺序执行的，那么，单核CPU是怎么执行多任务的呢？答案就是操作系统轮流让各个任务交替执行，任务1执行0.01秒，任务2执行0.01秒，再切换到任务3，执行0.01秒...，这样反复执行下去，表面上看，每个任务是交替执行的，但是由于CPU的执行速度非常快，我们就感觉所有的任务都是同时在执行一样。
  - 真正的并发执行多任务只能在多核CPU上实现，但是，由于任务数量远远大于CPU的核心数量，所以操作系统也会自动把很多任务轮流调度到每个核心上去执行。

#### 2、并发和并行

- 并发：指的是任务数多于cpu核数，通过操作系统的各种任务调度算法，实现多个任务“一起“执行（实现上总有一些任务不在执行，因为切换任务的速度相当快，看上去是一起在执行而已）

  ![](..\Images\erupt simultaneously.png)

- 并行：指的是任务数量小于cpu核数，即任务真的是一起在执行

![](..\Images\parallel.png)

##### 并发和并行处理任务时的差别

![](..\Images\process_threading.png)

#### 3.同步和异步

- **同步（同步协调）：是指线程在访问某一资源时，获得了资源的返回结果之后才会执行其它操作（先做某件事情，再做某件事情）**

- **异步：与同步相对，使之线程在访问某一资源时，无论是否获得了返回结果，都进行下一步的操作；当有了资源的返回结果时，系统会自动通知线程 。**

![](..\Images\sync_async.png)

![](..\Images\sync_async2.png)

##### 小结：

- 整整的并行执行多任务只能在多核cpu上实现，但是，由于任务数量远远多于CPU的核心线程数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。
- 并发：指的时任务数多于cpu核数，通过操作系统的各种任务调度算法，实现多个任务“一起”执行（实现上总有一些任务不在执行，因为切换任务的速度相当快，看上去是一起在执行而已）
- 并行：指的是任务数量小于cpu核数，即任务真的是一起在执行



#### 二、线程

- 问题：当前有两件事情要做，做事情一需要5秒钟，做事情二需要6秒钟

~~~python
import time


def func1():
    for i in range(5):
	print("---处理事情---")
    time.sleep(1)

    
def func2():
	for i in range(6):
		print("---处理事情---")
        time.sleep(1)
~~~

答案：使用多线程

##### 1.threading模块介绍

python中的threading模块时比较底层的模块，python的threading模块是对thread做了一些的封装，可以更加方便的被使用。

##### 创建线程：threading.Thread(target=func)

	- 参数target指定线程执行的任务（函数）

Thread类提供了以下的方法：

| 方法                      | 说明                                                         |
| ------------------------- | ------------------------------------------------------------ |
| run()                     | 用来表示线程活动的方法                                       |
| start()                   | 启动线程活动                                                 |
| join([time])              | 设置主线程会等待time秒后往下执行，time默认为子线程结束，多个子线程之间设置的值会叠加 |
| isAlive()                 | 返回线程 是否活动的                                          |
| getName()                 | 返回线程名称                                                 |
| threading.currentThread() | 返回当前执行的线程                                           |
| threading.enumerate()     | 返回正在运行的所有的线程（list） 正在运行的线程指启动前、结束后，不包括启动钱和终止后的线程 |
| threading.activeCount()   | 返回正在运行的线程数量                                       |

~~~python
import threading
from time import ctime, sleep


# 定义的学习的方法
def read_g(book, loop):
    for i in range(loop):
        print("Start reading %s %s" % (book, ctime()))
        sleep(2)


# 定义写的方法
def write_g(book, loop):
    for i in range(loop):
        #  .format() 格式符使用
        print("Starting writing {} {}" .format (book, ctime()))
        sleep(2)


def main():
    # 定义一个存放线程对象的列表
    thread = []
    # 实例化线程对象
    read_thread = threading.Thread(target=read_g, args=('python', 20))
    # 将线程对象放到容器中
    thread.append(read_thread)

    write_thread = threading.Thread(target=write_g, args=('java', 30))
    thread.append(write_thread)
    # 让容器中线程开始执行
    [thread_item.start() for thread_item in thread]

    # 主线程等待线程执行结束 释放资源  这一步必须 防止内存泄露
    [thread_item.join() for thread_item in thread]


if __name__ == "__main__":
    # 可以看出来 其为一起执行
    main()

~~~

##### 使用类来创建线程

~~~python
"""
    通过继承Thread类来创建线程
"""
import threading
import requests
import time


class RequestThread(threading.Thread):
    """发送requests请求"""

    def __init__(self, url):
        self.url = url
        # 传入自定义参数时，必须要继承父类的__init__方法,因为父类在__init__时会执行很多内部方法
        super().__init__()

    def run(self):
        """通过run方法来创建线程"""
        res = requests.get(self.url)
        print("线程：{}---返回的状态码为--{}--".format(threading.currentThread(), res.status_code))


if __name__ == "__main__":
    ulr = 'https://www.baidu.com'
    start_time = time.time()
    for i in range(3):
        t = RequestThread(ulr)
        t.start()
    t.join()
    end_time = time.time()
    print("耗时为{}".format(end_time - start_time))
~~~

#### 小结：

- 在一个进程内的所有线程共享全局变量，很方便在各个线程间共享数据
- 缺点就是：线程是对全局变量的随意修改可能造成多线程之间全局变量的混乱（即线程非安全）

多线程-共享全局变量的问题

> 问题：1000000次的bug
>
> ---创建线程之前 g_num is0---
>
> ---in work1,g_num为1088005---
>
> ---in work2,g_num为1286202---
>
> 2个线程对同一个全局变量的操作的最终结果为:1286202

**如果多个线程同时对全局变量进行操作，会出现资源竞争的问题，从而导致数据的不正确。**::fire:

**因此，由于Python中的多线程由于资源竞争导致的不安全性，该如何解决呢？**

> 答案：使用锁机制。

#### 三、同步&互斥锁 

- 控制线程的执行，避免同时获取数据

##### 同步

同步就是协同步调。按照预定的先后顺序进行运行。“同”在字面上容易理解为一起动作，其实不是，这里的“同”字是指协同、协助、相互配合。例如线程、进程同步，可以理解为进程或者线程A或者B一块合作，A执行到一定程度时需要依靠B这个结果，于是停下来，示意B运行，B运行后将结果返回給A，A收到结果后再继续执行。

#### 互斥锁

- 线程安全能够保证多个线程安全访问竞争资源，最简单的同步机制就是加入互斥锁。

- 互斥锁为资源引入一个状态：锁定/非锁定。

- 某个线程要更改共享数据时，先将其锁定，此时资源的状态为“锁定”，其它线程就不能更改知道线程释放该资源，将资源的状态修改为“非锁定”，其它的线程 才能再次锁定该资源。

- 互斥锁保证了每次只有一个线程可以写入操作，从而保证了多线程场景下数据的安全性和正确性。

- threading模块中定义了Lock类，可以方便的进行锁的创建，

  ~~~python
  import threading
  
  # 创建锁
  mutex = threading.Lock()
  
  # 锁定
  mutex.acquire()
  
  # 解锁
  mutex.release()
  ~~~

  

注意 ：

	 -  如果这个锁之前是没有锁定，那么acquire不会堵塞，下面中锁实例也是只有一个，两个线程会竞争同一个锁，谁用到了谁使用全局变量资源。

~~~python
import threading
import time

a = [100]

# 创建锁
lock = threading.Lock()


def fun1():
    global a
    for i in range(1000000):
        # 上锁
        lock.acquire()
        a[0] += 1
        # 修改完成 释放锁
        lock.release()
    print("线程一修改完a:{}".format(a))


def fun2():
    global a
    for i in range(4):
        lock.acquire()
        a[0] += 1
        lock.release()
    print("线程二修改完a:{}".format(1000000))


if __name__ == "__main__":
    t1 = threading.Thread(target=fun1, name="th_1")
    t2 = threading.Thread(target=fun1, name="th_2")
    t1.start()
    t2.start()
    t1.join()
    t2.join()

    print(a)

~~~

可以看到最后的结果，通过加入互斥锁后，其结果与预期相符。

- **上锁解锁过程**

  > - 当一个线程调用锁的acquire()方法时，锁就会进入“locked”状态。
  > - 每次只有一个线程可以获得锁。如果此时另外一个线程试图获取这个锁，该线程就会变为"blocked"状态，称为“阻塞”，直到拥有锁的线程调用锁的release()方法释放锁之后，锁进入“unlocked”状态。
  > - 线程调度程序从处于同步阻塞状态的线程中选择一个来获得锁，并使该线程进入到“running”状态

  总结：

  **锁的好处：**

  ​	确保了某段关键代码只能由一个线程从头到尾完整地执行

  **锁的坏处：**

  	- 阻止了多线程并发执行，包含锁地某段代码实际上只能以单线程模式运行，运行效率大大降低
  	- 由于存在多个锁，不同地线程持有不同的锁，并试图获取对方的锁时，可能会造成死锁。

##### 死锁：多个线程同时使用一个锁资源造成线程阻塞

~~~python
"""
	在不同的线程中同时使用一个锁导致阻塞 
"""
import threading
import time

a = [100]

# 创建锁
lock_a = threading.Lock()
lock_b = threading.Lock()


def fun1():
    global a
    for i in range(1000000):
        # 上锁
        lock_a.acquire()
        lock_b.acquire()
        
        a[0] += 1
        # 修改完成 释放锁
        lock_b.release()
        lock_b.release()
    print("线程一修改完a:{}".format(a))


def fun2():
    global a
    for i in range(4):
        lock_b.acquire()
        lock_a.acquire()
        a[0] += 1
        lock_a.release()
        lock_b.release()
    print("线程二修改完a:{}".format(1000000))


if __name__ == "__main__":
    t1 = threading.Thread(target=fun1, name="th_1")
    t2 = threading.Thread(target=fun1, name="th_2")
    t1.start()
    t2.start()
    t1.join()
    t2.join()

    print(a)

~~~



#### GIL(Python全局解释器锁)

###### GIL讨论如下：

> 描述Python GIL的概念，以及它对Python多线程的影响？

Guido的声明：http://www.artima.com/forums/flat.jsp?forum=106&thread=214235

参考答案 ：

> 1.Python语言和GIL没有半毛钱关系。仅仅是因为历史原因在CPython虚拟机（解释器）,难以移除GIL。
>
> 2.GIL：全局解释器锁，每个线程在执行的过程都需要先获取GIL，保证同一时刻只有一个线程可以执行代码。
>
> 3.线程释放GIL锁的情况: 在IO操作等可能会引起阻塞的system call之前，可以暂时释放GIL,但在执行完毕后，必须重新获取GIL(Python3.x使用计时器(达到阈值后，当前线程释放GIL))或者python2.x，使用计数器，tickets计数器达到100自动释放。
>
> 4.Python多进程只能使用CPU的一个核心，但是Python中的多进程可以使用CUP的多个核，因此搭配使用多进程+多线程来实现CPU核的最大利用率。 

##### 扩展：

##### 问题一：Python中单线程和多线程来完成通一个任务，哪个更快？

###### IO密集型  >  IO 密集型使用多线程，资源竞争；IO密集型 多线程比单线程运行效率高；IO密集型线程切换效率高

> 涉及到网络、磁盘IO的任务都是IO密集型，这类任务的特点是CPU消耗少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远大于CPU和内存的速度）

###### CPU密集型 >  CUP密集型使用多进程，最大化利用CPU核，最大化利用CPU计算力；CPU密集型单线程比多线程运行效率高；CPU密集型线程间切换开销大

> CPU密集型也称为计算密集型，这类任务的特点是需要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力

#### 四、队列

Python中的Queue模块提供了同步的，线程安全的队列类，包括 ：FIFO(FIRST IN FIRST OUT先进先出） LIFO(LAST IN FIRST OUT 后进先出 ）队列LifoQueue,优先级队列PriorityQueue，这些队列都实现了锁原理，可以在多线程中直接使用，可以使用对队列来实现线程间的同步。

初始化Queue()对象时，如q = Queue()，若括号中没有指定最大可接收的消息数量或者为负数，那么代表可接收的消息数量没有上限。

##### 队列的方法：

~~~python
def task_done(self):
    pass
def join(self):
    pass
def qsize(self):
    pass
def empty(self):
    pass
def full(self):
    pass
def put(self,item,block=True,timeout=None):
    pass
def get(self,block=True,time=None):
    pass
def put_nowait(self,item):
    pass
def get_nowait(self):
    pass 
~~~

- Queue.qsize()：返回当前队列包含的消息数量
- Queue.empty()：如果队列为空，返回True,否则返回False
- Queue.full() 如果队列满了，返回True,否则返回False
- Queue.get() 获取队列，timeout 等待时间

get(self, block=True, timeout=None):

block表示是否等待；timeout表示等待时间

- Queue.put(item):写入队列

put(self, block=True, timeout=None):

block表示是否等待；timeout表示等待时间

- Queue.get_nowait():相当于Queue.get(False)
- Queue.put_nowait(item):相当于 Queue.put(item,False)
- Queue.task_done()：在完成一项工作之后，使用Queue.task_done()方法可以向队列发送一个信号，表示该任务执行完毕
- Queue.join()实际上意味着等到队列中所有的任务（数据）都执行完毕后，再往下走，否则一值等待

三种基本的队列

![](..\Images\queue.png)

~~~python
# -*- coding:utf-8 -*-
"""
    三种队列
        1.先进先出
        2.后入先出
        3.优先级

"""
import queue

# FIFI 先进先出队列
from queue import Queue

# LIFO(后进先出队列)
from queue import LifoQueue

# 优先级别队列
from queue import PriorityQueue


def fifo_queue():
    """先进先出队列"""
    q = queue.Queue(3)
    q.put(1)
    q.put(2)
    q.put(3)
    # 推不进来导致阻塞,默认等待队列
    # q.put(4)

    # 不用等待，有错误直接抛出
    # q.put(4, block=False)

    # 和q.put(22, block=False)效果一致，表示向队列中添加数据不等待
    # q.put_nowait(22)

    # 获取队列中的数据
    print(q.get())
    print(q.get())
    print(q.get())

    # 队列中没有数据时，会导致阻塞
    # print(q.get())

    # 获取数据不等到，有问题直接抛出
    # print(q.get(block=False))
    # 和print(q.get(block=False))效果一致
    print(q.get_nowait())


def fifo_queue_1():
    """先进先出队列"""
    q = queue.Queue(8)
    q.put(1)
    q.put(2)
    q.put(3)
    q.put(4)
    q.put(5)
    q.put(6)
    # 获取队列中的任务数
    print(q.qsize())

    # 判断队列是否为空
    print(q.empty())

    # 判断队列是否已满
    print(q.full())

    # 又添加一个任务数
    q.put(12)
    print(q.qsize())

    q.put(3)
    print(q.full())
    print(q.empty())

    q.get(1)
    q.get(2)
    q.get(3)
    q.get(4)
    q.get(5)
    q.get(6)
    q.get(12)
    q.get(3)

    # 将队列中的任务都执行完毕
    # 任务完成调用此方法
    q.task_done()
    q.task_done()
    q.task_done()
    q.task_done()
    q.task_done()
    q.task_done()
    q.task_done()
    q.task_done()

    # 队列中的任务是否执行完毕，如果任务执行完毕，则返回None,否则阻塞
    print(q.join())


def lifo_queue():
    q = LifoQueue()
    q.put(1)
    q.put(2)
    q.put(3)

    print(q.get())
    print(q.get())
    print(q.get())


def priority_queue():
    q = PriorityQueue()
    
    # 以元组形式传入带等级的对象，第一个表示等级  (priority number, data).
    q.put((11, 'Hello11'))
    q.put((12, 'Hello12'))
    q.put((1, 'Hello1'))
    q.put((15, 'Hello15'))
    q.put((17, 'Hello17'))

    print(q.get())
    print(q.get())
    print(q.get())
    print(q.get())
    print(q.get())
    print(q.get())


if __name__ == "__main__":
    # fifo_queue()
    # fifo_queue_1()
    # lifo_queue()
    priority_queue()

~~~

